---
author: 'Lanxinmob'
title: '数据标注'
postSlug: 'shujubiaozhu'
tags:
  - '笔记'
  - 'ML'
description: '斯坦福实用机器学习1.4'
pubDatetime: 2025-07-25T09:00:00Z
---
## 半监督学习
- 半监督学习中，我们有少量带标签的数据和大量不带标签的数据。
- 为了标注这些数据，做了三个美好的假设。
### 基本假设
#### 流形假设 (Manifold Hypothesis)
- 我们所观测到的高维数据（例如一张图片的成千上万个像素点），实际上是由一个远低于其维度的低维**流形Manifold**嵌入在高维空间中形成的。处在同一个流形上的数据点，具有相似的性质和相同的标签。可以想象成纸折成团。
- 不要被高维的表象迷惑，去学习数据内在的低维结构。
#### 聚类假设 (Cluster Hypothesis)
- 数据在空间中会形成一个个簇（Cluster）。属于同一个簇的数据点，更有可能拥有相同的标签。
#### 连续性/平滑性假设 (Continuity/Smoothness Hypothesis)

- 相似的输入，应该有相似的输出，具体来说，如果两个数据点在输入空间中距离很近，那么它们对应的标签也应该大概率是相同的。

### 问题
- 问题在于数据并不一定满足这些假设，而在类似“自训练”（Self-Training）的方法中，模型会对无标签数据预测产生一个“伪标签”（Pseudo-Label）。如果模型对某个无标签样本做出了高置信度的错误预测，它会把这个错误的“伪标签”当作真实标签来进一步训练自己，越来越偏移正确的方向。

## 主动学习
- 面对大量无标签数据，它会主动挑选出最不确定的样本，然后提交给人类专家进行标注。标注完成后，再用这些高质量的新标签来训练自己。
### 挑选方法
#### 不确定性采样
- 最低置信度 (Least Confidence)：选择模型预测概率最低的那个样本。
#### 基于查询委员会的采样 (Query-By-Committee)
- 同时训练多个不同的模型对同一个无标签样本进行预测。那些让委员会成员分歧最大的样本被优先送去标注。

### 启发式(Heuristic)
- 指的是基于经验、直觉或规则的一种“估算”或“捷径”
- 对评论或邮件贴标签时，可以通过一些类似广告或欺诈的词来判断是不是spam，或者是一些正则来匹配需要的，如果有则是一类标签，如果没有则归于待贴标签。